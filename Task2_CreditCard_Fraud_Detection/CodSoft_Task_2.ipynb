{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Fge93bYXQD",
        "outputId": "ecd0c080-a9a2-41b3-dce0-9d4c4b2ab7bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'fraud-detection' dataset.\n",
            "Path to dataset files: /kaggle/input/fraud-detection\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kartik2112/fraud-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h-vu6iS9eZpY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1f3vFdTdVg4",
        "outputId": "0d3c7b79-6ef2-4cc9-b88a-f9247f4e204c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train file exists: True\n",
            "Test file exists: True\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = \"/kaggle/input/fraud-detection\"\n",
        "\n",
        "train_path =os.path.join(DATA_DIR, \"fraudTrain.csv\")\n",
        "test_path =os.path.join(DATA_DIR, \"fraudTest.csv\")\n",
        "\n",
        "print(\"Train file exists:\", os.path.exists(train_path))\n",
        "print(\"Test file exists:\", os.path.exists(test_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDflmsOsgaA3",
        "outputId": "0385a0bd-0752-46cb-9a67-f93421b33850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1296675, 23)\n",
            "Test shape: (555719, 23)\n",
            "\n",
            "Train columns:\n",
            " Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
            "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
            "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
            "       'merch_lat', 'merch_long', 'is_fraud'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "\n",
        "print(\"\\nTrain columns:\\n\", train_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r-FZkzhhYuq",
        "outputId": "1ac30d6d-f08f-4bb6-d199-7274d99f3bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined shape: (1852394, 24)\n"
          ]
        }
      ],
      "source": [
        "train_df[\"source\"] = \"train\"\n",
        "test_df[\"source\"]  = \"test\"\n",
        "\n",
        "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "print(\"\\nCombined shape:\", full_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzEeSMJKjSVh",
        "outputId": "da1bba78-0abf-48df-f8f4-608dd715f215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns after dropping some IDs/PII:\n",
            " Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
            "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
            "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
            "       'merch_lat', 'merch_long', 'is_fraud', 'source'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "cols_to_drop = [\"Unnamed: 0\", \"first\", \"last\", \"street\", \"dob\", \"trans_num\", \"trans_date_trans_time\"]\n",
        "\n",
        "print(\"\\nColumns after dropping some IDs/PII:\\n\", full_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKb1zl2WkP1Z",
        "outputId": "b82f581d-cf55-4d35-ea7e-96cd4dde046c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Categorical columns to encode:\n",
            " ['trans_date_trans_time', 'merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job', 'dob', 'trans_num', 'source']\n"
          ]
        }
      ],
      "source": [
        "cat_cols = full_df.select_dtypes(include=[\"object\"]).columns\n",
        "print(\"\\nCategorical columns to encode:\\n\", list(cat_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXUqoBddm8_c",
        "outputId": "7d5e844b-6747-48c5-8621-dce4513e5606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed train shape: (1296675, 22)\n",
            "Processed test shape : (555719, 22)\n",
            "\n",
            "Class distribution in training data:\n",
            "is_fraud\n",
            "0    0.994211\n",
            "1    0.005789\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "train_proc = full_df[full_df[\"source\"] == \"train\"].drop(columns=[\"source\"])\n",
        "test_proc  = full_df[full_df[\"source\"] == \"test\"].drop(columns=[\"source\"])\n",
        "\n",
        "X = train_proc.drop(columns=[\"is_fraud\"])\n",
        "y = train_proc[\"is_fraud\"]\n",
        "\n",
        "X_test_full = test_proc.drop(columns=[\"is_fraud\"])\n",
        "y_test_full = test_proc[\"is_fraud\"]\n",
        "\n",
        "print(\"\\nProcessed train shape:\", X.shape)\n",
        "print(\"Processed test shape :\", X_test_full.shape)\n",
        "\n",
        "print(\"\\nClass distribution in training data:\")\n",
        "print(y.value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i849LMBKoPAl",
        "outputId": "71aa949f-67a7-4206-fde3-20d2101cb257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train samples: 1037340\n",
            "val  samples: 259335\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\nTrain samples:\", X_train.shape[0])\n",
        "print('val  samples:', X_val.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H5WzdkOgq3fU"
      },
      "outputs": [],
      "source": [
        "non_numeric_cols = [\n",
        "    \"Unnamed: 0\",\n",
        "    \"trans_date_trans_time\",\n",
        "    \"cc_num\", # Often treated as an identifier, not a feature for scaling\n",
        "    \"merchant\",\n",
        "    \"category\",\n",
        "    \"first\",\n",
        "    \"last\",\n",
        "    \"gender\",\n",
        "    \"street\",\n",
        "    \"city\",\n",
        "    \"state\",\n",
        "    \"job\",\n",
        "    \"dob\",\n",
        "    \"trans_num\", # Often treated as an identifier, not a feature for scaling\n",
        "]\n",
        "\n",
        "# Ensure only numerical columns are passed to the scaler\n",
        "X_train_numeric = X_train.drop(columns=non_numeric_cols, errors='ignore')\n",
        "X_val_numeric   = X_val.drop(columns=non_numeric_cols, errors='ignore')\n",
        "X_test_full_numeric = X_test_full.drop(columns=non_numeric_cols, errors='ignore')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_numeric)\n",
        "X_val_scaled   = scaler.transform(X_val_numeric)\n",
        "X_test_scaled  = scaler.transform(X_test_full_numeric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kLxFzzMtqII7"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators = 200,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "}\n",
        "\n",
        "results = {}\n",
        "best_model = None\n",
        "best_name = None\n",
        "best_f1 = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYixDetqsQLV",
        "outputId": "67954e74-9e13-45ed-bb1c-c60b6bee6f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Logistic Regression Results:\n",
            "Accuracy : 0.9936992692849018\n",
            "Precision: 0.0\n",
            "Recall   : 0.0\n",
            "F1 Score : 0.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00    257834\n",
            "           1       0.00      0.00      0.00      1501\n",
            "\n",
            "    accuracy                           0.99    259335\n",
            "   macro avg       0.50      0.50      0.50    259335\n",
            "weighted avg       0.99      0.99      0.99    259335\n",
            "\n",
            "\n",
            "Training Decision Tree...\n",
            "Decision Tree Results:\n",
            "Accuracy : 0.9931748510613685\n",
            "Precision: 0.41535556954059155\n",
            "Recall   : 0.4397068620919387\n",
            "F1 Score : 0.42718446601941745\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    257834\n",
            "           1       0.42      0.44      0.43      1501\n",
            "\n",
            "    accuracy                           0.99    259335\n",
            "   macro avg       0.71      0.72      0.71    259335\n",
            "weighted avg       0.99      0.99      0.99    259335\n",
            "\n",
            "\n",
            "Training Random Forest...\n",
            "Random Forest Results:\n",
            "Accuracy : 0.9959319027512676\n",
            "Precision: 0.7973333333333333\n",
            "Recall   : 0.3984010659560293\n",
            "F1 Score : 0.5313194135939583\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    257834\n",
            "           1       0.80      0.40      0.53      1501\n",
            "\n",
            "    accuracy                           1.00    259335\n",
            "   macro avg       0.90      0.70      0.76    259335\n",
            "weighted avg       1.00      1.00      1.00    259335\n",
            "\n",
            "\n",
            "============================\n",
            "Validation Results Summary:\n",
            "Logistic Regression -> F1: 0.0 | Acc: 0.9936992692849018\n",
            "Decision Tree -> F1: 0.42718446601941745 | Acc: 0.9931748510613685\n",
            "Random Forest -> F1: 0.5313194135939583 | Acc: 0.9959319027512676\n",
            "============================\n",
            "Best model on validation set: Random Forest with F1 = 0.5313194135939583\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "best_f1 = 0.0\n",
        "best_model = None\n",
        "best_name = \"\"\n",
        "\n",
        "# 1) Logistic Regression\n",
        "print(\"Training Logistic Regression...\")\n",
        "log_model = LogisticRegression(max_iter=1000)\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_val_pred = log_model.predict(X_val_scaled)\n",
        "\n",
        "acc = accuracy_score(y_val, y_val_pred)\n",
        "prec = precision_score(y_val, y_val_pred, zero_division=0)\n",
        "rec = recall_score(y_val, y_val_pred, zero_division=0)\n",
        "f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
        "\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(\"Accuracy :\", acc)\n",
        "print(\"Precision:\", prec)\n",
        "print(\"Recall   :\", rec)\n",
        "print(\"F1 Score :\", f1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "results[\"Logistic Regression\"] = {\n",
        "    \"accuracy\": acc,\n",
        "    \"precision\": prec,\n",
        "    \"recall\": rec,\n",
        "    \"f1\": f1\n",
        "}\n",
        "\n",
        "if f1 > best_f1:\n",
        "    best_f1 = f1\n",
        "    best_model = log_model\n",
        "    best_name = \"Logistic Regression\"\n",
        "\n",
        "\n",
        "# 2) Decision Tree\n",
        "print(\"\\nTraining Decision Tree...\")\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_val_pred = dt_model.predict(X_val_scaled)\n",
        "\n",
        "acc = accuracy_score(y_val, y_val_pred)\n",
        "prec = precision_score(y_val, y_val_pred, zero_division=0)\n",
        "rec = recall_score(y_val, y_val_pred, zero_division=0)\n",
        "f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
        "\n",
        "print(\"Decision Tree Results:\")\n",
        "print(\"Accuracy :\", acc)\n",
        "print(\"Precision:\", prec)\n",
        "print(\"Recall   :\", rec)\n",
        "print(\"F1 Score :\", f1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "results[\"Decision Tree\"] = {\n",
        "    \"accuracy\": acc,\n",
        "    \"precision\": prec,\n",
        "    \"recall\": rec,\n",
        "    \"f1\": f1\n",
        "}\n",
        "\n",
        "if f1 > best_f1:\n",
        "    best_f1 = f1\n",
        "    best_model = dt_model\n",
        "    best_name = \"Decision Tree\"\n",
        "\n",
        "\n",
        "# 3) Random Forest\n",
        "print(\"\\nTraining Random Forest...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_val_pred = rf_model.predict(X_val_scaled)\n",
        "\n",
        "acc = accuracy_score(y_val, y_val_pred)\n",
        "prec = precision_score(y_val, y_val_pred, zero_division=0)\n",
        "rec = recall_score(y_val, y_val_pred, zero_division=0)\n",
        "f1 = f1_score(y_val, y_val_pred, zero_division=0)\n",
        "\n",
        "print(\"Random Forest Results:\")\n",
        "print(\"Accuracy :\", acc)\n",
        "print(\"Precision:\", prec)\n",
        "print(\"Recall   :\", rec)\n",
        "print(\"F1 Score :\", f1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "results[\"Random Forest\"] = {\n",
        "    \"accuracy\": acc,\n",
        "    \"precision\": prec,\n",
        "    \"recall\": rec,\n",
        "    \"f1\": f1\n",
        "}\n",
        "\n",
        "if f1 > best_f1:\n",
        "    best_f1 = f1\n",
        "    best_model = rf_model\n",
        "    best_name = \"Random Forest\"\n",
        "\n",
        "\n",
        "# Summary\n",
        "print(\"Validation Results Summary:\")\n",
        "for name in results:\n",
        "    print(name, \"-> F1:\", results[name][\"f1\"], \"| Acc:\", results[name][\"accuracy\"])\n",
        "\n",
        "print(\"Best model on validation set:\", best_name, \"with F1 =\", best_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxi_nQei4SuU",
        "outputId": "a13007c6-ddae-4325-f6ae-3c736879ee10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the best model: Random Forest\n",
            "Test Results:\n",
            "Accuracy : 0.9956308853935172\n",
            "Precision: 0.29756795422031473\n",
            "Recall   : 0.09696969696969697\n",
            "F1 Score : 0.14627285513361463\n",
            "ROC AUC  : 0.8253077583418242\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    553574\n",
            "           1       0.30      0.10      0.15      2145\n",
            "\n",
            "    accuracy                           1.00    555719\n",
            "   macro avg       0.65      0.55      0.57    555719\n",
            "weighted avg       0.99      1.00      0.99    555719\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[553083    491]\n",
            " [  1937    208]]\n"
          ]
        }
      ],
      "source": [
        "# Testing on test dataset\n",
        "print(\"Evaluating the best model:\", best_name)\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Check accuracy, precision, recall, f1\n",
        "test_acc = accuracy_score(y_test_full, y_test_pred)\n",
        "test_prec = precision_score(y_test_full, y_test_pred, zero_division=0)\n",
        "test_rec = recall_score(y_test_full, y_test_pred, zero_division=0)\n",
        "test_f1 = f1_score(y_test_full, y_test_pred, zero_division=0)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(\"Accuracy :\", test_acc)\n",
        "print(\"Precision:\", test_prec)\n",
        "print(\"Recall   :\", test_rec)\n",
        "print(\"F1 Score :\", test_f1)\n",
        "\n",
        "if hasattr(best_model, \"predict_proba\"):\n",
        "    y_test_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    test_roc_auc = roc_auc_score(y_test_full, y_test_proba)\n",
        "    print(\"ROC AUC  :\", test_roc_auc)\n",
        "else:\n",
        "    print(\"ROC AUC  : Not available for this model\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_full, y_test_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_full, y_test_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}